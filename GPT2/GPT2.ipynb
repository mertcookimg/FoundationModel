{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " ## 0. 準備\n",
        " Huggingface Transformersとftfyをpipを用いてインストールします。"
      ],
      "metadata": {
        "id": "bY1l9mDO9fzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.6.0\n",
        "!pip install ftfy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJLOutAy9pgL",
        "outputId": "25830be7-8d75-4cf6-b301-e5f185bff666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.6.0\n",
            "  Downloading transformers-4.6.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.6.0) (2.25.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.6.0) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.6.0) (4.64.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.6.0) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.6.0) (2022.6.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==4.6.0) (23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.6.0) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.6.0) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.6.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.6.0) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.6.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.6.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.6.0) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=2c3da3420a35fa27fa6c46ae28530450020d12954cbfb4140c0e1d78b5d7a6b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy) (0.2.6)\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 基盤モデル (Language )"
      ],
      "metadata": {
        "id": "idbcZTPp2Esb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. GPT2を体感\n",
        "\n",
        "GPT2を活用して文章生成をしてみましょう！\n",
        "\n",
        "目的：GPT2を活用して文章の続きを生成してくれる様子を体感する。\n",
        "\n",
        "参考サイト：https://huggingface.co/gpt2\n",
        "This is the smallest version of GPT-2, with 124M parameters.\n"
      ],
      "metadata": {
        "id": "nKs9Q6Rmi9gJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 文章生成"
      ],
      "metadata": {
        "id": "cDqMK98xFjFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "#gpt2\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "#シードを固定\n",
        "set_seed(42)\n",
        "#max_length 文の長さ, num_return_sequences 生成文の数\n",
        "generator(\"Hello, I'm a language model,\", max_length=20, num_return_sequences=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "3af145dccede46f3aeb15a660da90686",
            "d30ddc32307f470fa9e2c90ab7035319",
            "9604632e18444f7287fcfa5b65c6ac60",
            "4f72e9ddea9b44c7bfad58b03948f630",
            "2b0a01a70fe64bfcad677f2930efcce6",
            "c92af47940824b498c2e00e39648a324",
            "c1caae5fda8649d9bd239660c0cf2bd1",
            "9205b990196a4019b533610ee7b22d51",
            "bcb2563da4c948e1a9eb8e55b59ff68a",
            "1242460c908a4f718431592ddbaebb82",
            "2a0a3d73c51745d2b2b41b9ecc0871e2",
            "48bbd395474e454cb65f77a62df1dbfa",
            "0bc5f2f08dee41438e1de1b65e68f84b",
            "53f1536285804f898c95216ccaf05135",
            "370cd02c0505458c833033ebbef4a042",
            "3330ad504e224c27b064f159239f11da",
            "c1a56c86845942d5bb7bc0159efc9776",
            "4afc3fec043f4dfbbe47378c04f560d3",
            "12c57782318a4b08aea4f8c92476452b",
            "bb6e0453649540f79dedf32cfbd3970e",
            "8e6dfaa366454fe5989251e4a56f919a",
            "5e2849f298a943b785d1f7280b2a002f",
            "e27a658218934e5eb4bf930b98927786",
            "88e28af275514e568a08aa815cdfc004",
            "e0f1b33d58fa41ee82f13d039f72466e",
            "dc08de98e15849709ab768eb4c76a469",
            "a123fe074faf40d8b01258182c14a3b8",
            "1ce0c52ba7cf4381972df3006f1be76a",
            "54029ed0b686416eaa64b190b7b04569",
            "e2e260ea92c940cb80dcd4f13f71d4dd",
            "ee4227dc58e54f7fb0d1be57361e19e5",
            "e9964c15b15740c9a311c5f81cbf29d9",
            "566b17c857bb46b1930b9a0e93ceaf61",
            "6623df79ad9e4cb789fb6c87b6f4ec9c",
            "149ab12b57e247a89bcdbe07e2ddf4ce",
            "0e6c1c7f2ed741dd9b8df8cfd1695ad1",
            "5bec7c3b257e4b27ad2e52db541f94cc",
            "526a1f72a2db489d8591fdb0a6c8d709",
            "219f18b566dd4d4ea437faee1641b529",
            "d18c134a20cc456fbc6e8951dca48299",
            "daa43790e8ca45c486cbdd088e164be4",
            "c7d67338bde344be967cab4e06226166",
            "f52eae894b8f4ccc8a5046ac362c7d22",
            "728394c487c7444596a64bcc6de918d0",
            "4b3f4711488a42198419bc643ec6a192",
            "53bdbf2d70944694bbab9c12b409fdc5",
            "f173c80457cb4877adf2844387912ef6",
            "62a7e61d77524844be24b1130857156e",
            "641ac2fb09354a928f9c2196ac9658a7",
            "7c77e78da3b44355abe2d23b03d32b66",
            "f28192cb218c44ff9d7c39cd9a2da4e8",
            "bbe11bbe34a14907ad78d7663aa9c070",
            "7d1bd9041d794719b97b6ee0e31cbf98",
            "084d73acdbf1406c99512c68a22654ad",
            "160c5192553d4276ae7083f2511ceae5"
          ]
        },
        "id": "eKkXO3mOkLx8",
        "outputId": "3618a936-bb23-4eee-db4c-8843c0877830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3af145dccede46f3aeb15a660da90686"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48bbd395474e454cb65f77a62df1dbfa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e27a658218934e5eb4bf930b98927786"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6623df79ad9e4cb789fb6c87b6f4ec9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b3f4711488a42198419bc643ec6a192"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"Hello, I'm a language model, I work in front-end development. I wanted to keep\"},\n",
              " {'generated_text': \"Hello, I'm a language model, and I know what it is like for the human form.\"},\n",
              " {'generated_text': 'Hello, I\\'m a language model, so I will call you.\"\\n\\nI nodded, and'}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##演習1\n",
        "テキストやパラメータを変更してみましょう。\n",
        "max_length 文の長さ, num_return_sequences 生成文の数"
      ],
      "metadata": {
        "id": "7SQefo2PjOq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "set_seed(42)\n",
        "generator(\"You can use this model directly with \", max_length=20, num_return_sequences=3)"
      ],
      "metadata": {
        "id": "_QVo9nP_jZW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c08d75fe-714b-4f6c-c980-c5cc91065bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'You can use this model directly with xtrees in JavaScript to convert these HTML5 views into a'},\n",
              " {'generated_text': 'You can use this model directly with iphone X11, and can get the full power of'},\n",
              " {'generated_text': 'You can use this model directly with ichter.py or directly. It works for all python'}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}